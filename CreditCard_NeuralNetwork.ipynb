{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../input/creditcard.csv\",header = 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud\n",
      "count       492.000000\n",
      "mean      80746.806911\n",
      "std       47835.365138\n",
      "min         406.000000\n",
      "25%       41241.500000\n",
      "50%       75568.500000\n",
      "75%      128483.000000\n",
      "max      170348.000000\n",
      "Name: Time, dtype: float64\n",
      "\n",
      "Normal\n",
      "count    284315.000000\n",
      "mean      94838.202258\n",
      "std       47484.015786\n",
      "min           0.000000\n",
      "25%       54230.000000\n",
      "50%       84711.000000\n",
      "75%      139333.000000\n",
      "max      172792.000000\n",
      "Name: Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Fraud\")\n",
    "print (data.Time[data.Class == 1].describe())\n",
    "print ()\n",
    "print (\"Normal\")\n",
    "print (data.Time[data.Class == 0].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAETCAYAAADqPbqrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e01ba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "\n",
    "bins = 50\n",
    "\n",
    "ax1.hist(data.Time[data.Class == 1], bins = bins)\n",
    "ax1.set_title('Fraud')\n",
    "\n",
    "ax2.hist(data.Time[data.Class == 0], bins = bins)\n",
    "ax2.set_title('Normal')\n",
    "\n",
    "plt.xlabel('Time (in Seconds)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Time' feature looks pretty similar across both types of transactions. You could argue that fraudulent transactions are more uniformly distributed, while normal transactions have a cyclical distribution. This could make it easier to detect a fraudulent transaction during at an 'off-peak' time.\n",
    "\n",
    "Now let's see if the transaction amount differs between the two types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "Normal\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (\"Fraud\")\n",
    "print (data.Amount[data.Class == 1].describe())\n",
    "print ()\n",
    "print (\"Normal\")\n",
    "print (data.Amount[data.Class == 0].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAEUCAYAAADtBGqdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEI0AAAA4CBCNAAAAOAgQjQAAADgoP8HLIi8dRRkMDQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1275c38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
    "\n",
    "bins = 30\n",
    "\n",
    "ax1.hist(data.Amount[data.Class == 1], bins = bins)\n",
    "ax1.set_title('Fraud')\n",
    "\n",
    "ax2.hist(data.Amount[data.Class == 0], bins = bins)\n",
    "ax2.set_title('Normal')\n",
    "\n",
    "plt.xlabel('Amount ($)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Amount_max_fraud'] = 1\n",
    "data.loc[data.Amount <= 2125.87, 'Amount_max_fraud'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most transactions are small amounts, less than 100.Fraudulent transactions have a max value far less than normal transactions (2,125.87 vs $25,691.16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop all of the features that have very similar distributions between the two types of transactions.\n",
    "data = data.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Based on the plots above, these features are created to identify values where fraudulent transaction are more common.\n",
    "data['V1_'] = data.V1.map(lambda x: 1 if x < -3 else 0)\n",
    "data['V2_'] = data.V2.map(lambda x: 1 if x > 2.5 else 0)\n",
    "data['V3_'] = data.V3.map(lambda x: 1 if x < -4 else 0)\n",
    "data['V4_'] = data.V4.map(lambda x: 1 if x > 2.5 else 0)\n",
    "data['V5_'] = data.V5.map(lambda x: 1 if x < -4.5 else 0)\n",
    "data['V6_'] = data.V6.map(lambda x: 1 if x < -2.5 else 0)\n",
    "data['V7_'] = data.V7.map(lambda x: 1 if x < -3 else 0)\n",
    "data['V9_'] = data.V9.map(lambda x: 1 if x < -2 else 0)\n",
    "data['V10_'] = data.V10.map(lambda x: 1 if x < -2.5 else 0)\n",
    "data['V11_'] = data.V11.map(lambda x: 1 if x > 2 else 0)\n",
    "data['V12_'] = data.V12.map(lambda x: 1 if x < -2 else 0)\n",
    "data['V14_'] = data.V14.map(lambda x: 1 if x < -2.5 else 0)\n",
    "data['V16_'] = data.V16.map(lambda x: 1 if x < -2 else 0)\n",
    "data['V17_'] = data.V17.map(lambda x: 1 if x < -2 else 0)\n",
    "data['V18_'] = data.V18.map(lambda x: 1 if x < -2 else 0)\n",
    "data['V19_'] = data.V19.map(lambda x: 1 if x > 1.5 else 0)\n",
    "data['V21_'] = data.V21.map(lambda x: 1 if x > 0.6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a new feature for normal (non-fraudulent) transactions.\n",
    "data.loc[data.Class == 0, 'Normal'] = 1\n",
    "data.loc[data.Class == 1, 'Normal'] = 0\n",
    "#Rename 'Class' to 'Fraud'.\n",
    "data = data.rename(columns={'Class': 'Fraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    284315\n",
      "0.0       492\n",
      "Name: Normal, dtype: int64\n",
      "\n",
      "0    284315\n",
      "1       492\n",
      "Name: Fraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#492 fraudulent transactions, 284,315 normal transactions.\n",
    "#0.172% of transactions were fraud. \n",
    "print(data.Normal.value_counts())\n",
    "print()\n",
    "print(data.Fraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V21</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Amount_max_fraud</th>\n",
       "      <th>V1_</th>\n",
       "      <th>V2_</th>\n",
       "      <th>V3_</th>\n",
       "      <th>V4_</th>\n",
       "      <th>V5_</th>\n",
       "      <th>V6_</th>\n",
       "      <th>V7_</th>\n",
       "      <th>V9_</th>\n",
       "      <th>V10_</th>\n",
       "      <th>V11_</th>\n",
       "      <th>V12_</th>\n",
       "      <th>V14_</th>\n",
       "      <th>V16_</th>\n",
       "      <th>V17_</th>\n",
       "      <th>V18_</th>\n",
       "      <th>V19_</th>\n",
       "      <th>V21_</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V9       V10       V11       V12       V14       V16       V17  \\\n",
       "0  0.363787  0.090794 -0.551600 -0.617801 -0.311169 -0.470401  0.207971   \n",
       "1 -0.255425 -0.166974  1.612727  1.065235 -0.143772  0.463917 -0.114805   \n",
       "2 -1.514654  0.207643  0.624501  0.066084 -0.165946 -2.890083  1.109969   \n",
       "3 -1.387024 -0.054952 -0.226487  0.178228 -0.287924 -1.059647 -0.684093   \n",
       "4  0.817739  0.753074 -0.822843  0.538196 -1.119670 -0.451449 -0.237033   \n",
       "\n",
       "        V18       V19       V21  Amount  Fraud  Amount_max_fraud  V1_  V2_  \\\n",
       "0  0.025791  0.403993 -0.018307  149.62      0                 0    0    0   \n",
       "1 -0.183361 -0.145783 -0.225775    2.69      0                 0    0    0   \n",
       "2 -0.121359 -2.261857  0.247998  378.66      0                 0    0    0   \n",
       "3  1.965775 -1.232622 -0.108300  123.50      0                 0    0    0   \n",
       "4 -0.038195  0.803487 -0.009431   69.99      0                 0    0    0   \n",
       "\n",
       "   V3_  V4_  V5_  V6_  V7_  V9_  V10_  V11_  V12_  V14_  V16_  V17_  V18_  \\\n",
       "0    0    0    0    0    0    0     0     0     0     0     0     0     0   \n",
       "1    0    0    0    0    0    0     0     0     0     0     0     0     0   \n",
       "2    0    0    0    0    0    0     0     0     0     0     1     0     0   \n",
       "3    0    0    0    0    0    0     0     0     0     0     0     0     0   \n",
       "4    0    0    0    0    0    0     0     0     0     0     0     0     0   \n",
       "\n",
       "   V19_  V21_  Normal  \n",
       "0     0     0     1.0  \n",
       "1     0     0     1.0  \n",
       "2     0     0     1.0  \n",
       "3     0     0     1.0  \n",
       "4     0     0     1.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\",101)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dataframes of only Fraud and Normal transactions.\n",
    "Fraud = data[data.Fraud == 1]\n",
    "Normal = data[data.Normal == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set X_train equal to 80% of the fraudulent transactions.\n",
    "X_train = Fraud.sample(frac=0.8)\n",
    "count_Frauds = len(X_train)\n",
    "\n",
    "# Add 80% of the normal transactions to X_train.\n",
    "X_train = pd.concat([X_train, Normal.sample(frac = 0.8)], axis = 0)\n",
    "\n",
    "# X_test contains all the transaction not in X_train.\n",
    "X_test = data.loc[~data.index.isin(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle the dataframes so that the training is done in a random order.\n",
    "X_train = shuffle(X_train)\n",
    "X_test = shuffle(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add our target features to y_train and y_test.\n",
    "y_train = X_train.Fraud\n",
    "y_train = pd.concat([y_train, X_train.Normal], axis=1)\n",
    "\n",
    "y_test = X_test.Fraud\n",
    "y_test = pd.concat([y_test, X_test.Normal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop target features from X_train and X_test.\n",
    "X_train = X_train.drop(['Fraud','Normal'], axis = 1)\n",
    "X_test = X_test.drop(['Fraud','Normal'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227846\n",
      "227846\n",
      "56961\n",
      "56961\n"
     ]
    }
   ],
   "source": [
    "#Check to ensure all of the training/testing dataframes are of the correct length\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Due to the imbalance in the data, ratio will act as an equal weighting system for our model. \n",
    "By dividing the number of transactions by those that are fraudulent, ratio will equal the value that when multiplied\n",
    "by the number of fraudulent transactions will equal the number of normal transaction. \n",
    "Simply put: # of fraud * ratio = # of normal\n",
    "'''\n",
    "ratio = len(X_train)/count_Frauds \n",
    "\n",
    "y_train.Fraud *= ratio\n",
    "y_test.Fraud *= ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Names of all of the features in X_train.\n",
    "features = X_train.columns.values\n",
    "\n",
    "#Transform each feature in features so that it has a mean of 0 and standard deviation of 1; \n",
    "#this helps with training the neural network.\n",
    "for feature in features:\n",
    "    mean, std = data[feature].mean(), data[feature].std()\n",
    "    X_train.loc[:, feature] = (X_train[feature] - mean) / std\n",
    "    X_test.loc[:, feature] = (X_test[feature] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the testing data into validation and testing sets\n",
    "split = int(len(y_test)/2)\n",
    "\n",
    "inputX = X_train.as_matrix()\n",
    "inputY = y_train.as_matrix()\n",
    "inputX_valid = X_test.as_matrix()[:split]\n",
    "inputY_valid = y_test.as_matrix()[:split]\n",
    "inputX_test = X_test.as_matrix()[split:]\n",
    "inputY_test = y_test.as_matrix()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of input nodes.\n",
    "input_nodes = 37\n",
    "\n",
    "# Multiplier maintains a fixed ratio of nodes between each layer.\n",
    "mulitplier = 1.5 \n",
    "\n",
    "# Number of nodes in each hidden layer\n",
    "hidden_nodes1 = 18\n",
    "hidden_nodes2 = round(hidden_nodes1 * mulitplier)\n",
    "hidden_nodes3 = round(hidden_nodes2 * mulitplier)\n",
    "\n",
    "# Percent of nodes to keep during dropout.\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "\n",
    "# layer 1\n",
    "W1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_nodes1], stddev = 0.15))\n",
    "b1 = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n",
    "\n",
    "# layer 2\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2], stddev = 0.15))\n",
    "b2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)\n",
    "\n",
    "# layer 3\n",
    "W3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3], stddev = 0.15)) \n",
    "b3 = tf.Variable(tf.zeros([hidden_nodes3]))\n",
    "y3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)\n",
    "y3 = tf.nn.dropout(y3, pkeep)\n",
    "\n",
    "# layer 4\n",
    "W4 = tf.Variable(tf.truncated_normal([hidden_nodes3, 2], stddev = 0.15)) \n",
    "b4 = tf.Variable(tf.zeros([2]))\n",
    "y4 = tf.nn.softmax(tf.matmul(y3, W4) + b4)\n",
    "\n",
    "# output\n",
    "y = y4\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "training_epochs = 5 # should be 2000, it will timeout when uploading\n",
    "training_dropout = 0.9\n",
    "display_step = 1 # 10 \n",
    "n_samples = y_train.shape[0]\n",
    "batch_size = 2048\n",
    "learning_rate = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost function: Cross Entropy\n",
    "cost = -tf.reduce_sum(y_ * tf.log(y))\n",
    "\n",
    "# We will optimize our model via AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Correct prediction if the most likely value (Fraud or Normal) from softmax equals the target value.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Acc = 0.92134 Cost = 89850.33594 Valid_Acc = 0.92177 Valid_Cost =  13511.37012\n",
      "Epoch: 1 Acc = 0.94275 Cost = 66175.21094 Valid_Acc = 0.94280 Valid_Cost =  12721.86328\n",
      "Epoch: 2 Acc = 0.93886 Cost = 63929.50000 Valid_Acc = 0.93954 Valid_Cost =  12989.94629\n",
      "Epoch: 3 Acc = 0.95432 Cost = 58242.87891 Valid_Acc = 0.95551 Valid_Cost =  13772.51953\n",
      "Epoch: 4 Acc = 0.93968 Cost = 59782.32422 Valid_Acc = 0.93943 Valid_Cost =  13300.77930\n",
      "\n",
      "Optimization Finished!\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ..input/best_model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on ..input/best_model.ckpt: Not found: ..input\n\t [[Node: save_6/RestoreV2_155 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_6/Const_0_0, save_6/RestoreV2_155/tensor_names, save_6/RestoreV2_155/shape_and_slices)]]\n\nCaused by op 'save_6/RestoreV2_155', defined at:\n  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-157-8975e1008252>\", line 9, in <module>\n    saver = tf.train.Saver(max_to_keep=1)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on ..input/best_model.ckpt: Not found: ..input\n\t [[Node: save_6/RestoreV2_155 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_6/Const_0_0, save_6/RestoreV2_155/tensor_names, save_6/RestoreV2_155/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ..input/best_model.ckpt: Not found: ..input\n\t [[Node: save_6/RestoreV2_155 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_6/Const_0_0, save_6/RestoreV2_155/tensor_names, save_6/RestoreV2_155/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-8975e1008252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Load the best weights and show its results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_dropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1548\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ..input/best_model.ckpt: Not found: ..input\n\t [[Node: save_6/RestoreV2_155 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_6/Const_0_0, save_6/RestoreV2_155/tensor_names, save_6/RestoreV2_155/shape_and_slices)]]\n\nCaused by op 'save_6/RestoreV2_155', defined at:\n  File \"/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-157-8975e1008252>\", line 9, in <module>\n    saver = tf.train.Saver(max_to_keep=1)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1139, in __init__\n    self.build()\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on ..input/best_model.ckpt: Not found: ..input\n\t [[Node: save_6/RestoreV2_155 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save_6/Const_0_0, save_6/RestoreV2_155/tensor_names, save_6/RestoreV2_155/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_summary = [] # Record accuracy values for plot\n",
    "cost_summary = [] # Record cost values for plot\n",
    "valid_accuracy_summary = [] \n",
    "valid_cost_summary = [] \n",
    "stop_early = 0 # To keep track of the number of epochs before early stopping\n",
    "\n",
    "# Save the best weights so that they can be used to make the final predictions\n",
    "checkpoint = \"..input/best_model.ckpt\"\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "# Initialize variables and tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs): \n",
    "        for batch in range(int(n_samples/batch_size)):\n",
    "            batch_x = inputX[batch*batch_size : (1+batch)*batch_size]\n",
    "            batch_y = inputY[batch*batch_size : (1+batch)*batch_size]\n",
    "\n",
    "            sess.run([optimizer], feed_dict={x: batch_x, \n",
    "                                             y_: batch_y,\n",
    "                                             pkeep: training_dropout})\n",
    "\n",
    "        # Display logs after every 10 epochs\n",
    "        if (epoch) % display_step == 0:\n",
    "            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={x: inputX, \n",
    "                                                                            y_: inputY,\n",
    "                                                                            pkeep: training_dropout})\n",
    "\n",
    "            valid_accuracy, valid_newCost = sess.run([accuracy, cost], feed_dict={x: inputX_valid, \n",
    "                                                                                  y_: inputY_valid,\n",
    "                                                                                  pkeep: 1})\n",
    "\n",
    "            print (\"Epoch:\", epoch,\n",
    "                   \"Acc =\", \"{:.5f}\".format(train_accuracy), \n",
    "                   \"Cost =\", \"{:.5f}\".format(newCost),\n",
    "                   \"Valid_Acc =\", \"{:.5f}\".format(valid_accuracy), \n",
    "                   \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost))\n",
    "            \n",
    "            # Save the weights if these conditions are met.\n",
    "            if epoch > 0 and valid_accuracy > max(valid_accuracy_summary) and valid_accuracy > 0.999:\n",
    "                saver.save(sess, checkpoint)\n",
    "            \n",
    "            # Record the results of the model\n",
    "            accuracy_summary.append(train_accuracy)\n",
    "            cost_summary.append(newCost)\n",
    "            valid_accuracy_summary.append(valid_accuracy)\n",
    "            valid_cost_summary.append(valid_newCost)\n",
    "            \n",
    "            # If the model does not improve after 15 logs, stop the training.\n",
    "            if valid_accuracy < max(valid_accuracy_summary) and epoch > 100:\n",
    "                stop_early += 1\n",
    "                if stop_early == 15:\n",
    "                    break\n",
    "            else:\n",
    "                stop_early = 0\n",
    "            \n",
    "    print()\n",
    "    print(\"Optimization Finished!\")\n",
    "    print()   \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    # Load the best weights and show its results\n",
    "    saver.restore(sess, checkpoint)\n",
    "    training_accuracy = sess.run(accuracy, feed_dict={x: inputX, y_: inputY, pkeep: training_dropout})\n",
    "    validation_accuracy = sess.run(accuracy, feed_dict={x: inputX_valid, y_: inputY_valid, pkeep: 1})\n",
    "    \n",
    "    print(\"Results using the best Valid_Acc:\")\n",
    "    print()\n",
    "    print(\"Training Accuracy =\", training_accuracy)\n",
    "    print(\"Validation Accuracy =\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the accuracy and cost summaries \n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,4))\n",
    "\n",
    "ax1.plot(accuracy_summary) # blue\n",
    "ax1.plot(valid_accuracy_summary) # green\n",
    "ax1.set_title('Accuracy')\n",
    "\n",
    "ax2.plot(cost_summary)\n",
    "ax2.plot(valid_cost_summary)\n",
    "ax2.set_title('Cost')\n",
    "\n",
    "plt.xlabel('Epochs (x10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the predicted values, then use them to build a confusion matrix\n",
    "predicted = tf.argmax(y, 1)\n",
    "with tf.Session() as sess:  \n",
    "   # Load the best weights\n",
    "   saver.restore(sess, checkpoint)\n",
    "   testing_predictions, testing_accuracy = sess.run([predicted, accuracy], \n",
    "                                                    feed_dict={x: inputX_test, y_:inputY_test, pkeep: 1})\n",
    "   \n",
    "   print(\"F1-Score =\", f1_score(inputY_test[:,1], testing_predictions))\n",
    "   print(\"Testing Accuracy =\", testing_accuracy)\n",
    "   print()\n",
    "   c = confusion_matrix(inputY_test[:,1], testing_predictions)\n",
    "   show_confusion_matrix(c, ['Fraud', 'Normal'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reload the original dataset\n",
    "tsne_data = pd.read_csv(\"../input/creditcard.csv\")\n",
    "\n",
    "#Set df2 equal to all of the fraulent and 10,000 normal transactions.\n",
    "df2 = tsne_data[tsne_data.Class == 1]\n",
    "df2 = pd.concat([df2, tsne_data[tsne_data.Class == 0].sample(n = 10000)], axis = 0)\n",
    "\n",
    "#Scale features to improve the training ability of TSNE.\n",
    "standard_scaler = StandardScaler()\n",
    "df2_std = standard_scaler.fit_transform(df2)\n",
    "\n",
    "#Set y equal to the target values.\n",
    "y = df2.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "x_test_2d = tsne.fit_transform(df2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the scatter plot with the two types of transactions.\n",
    "color_map = {0:'red', 1:'blue'}\n",
    "plt.figure()\n",
    "for idx, cl in enumerate(np.unique(y)):\n",
    "    plt.scatter(x = x_test_2d[y==cl,0], \n",
    "                y = x_test_2d[y==cl,1], \n",
    "                c = color_map[idx], \n",
    "                label = cl)\n",
    "plt.xlabel('X in t-SNE')\n",
    "plt.ylabel('Y in t-SNE')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('t-SNE visualization of test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are two main groupings of fraudulent transactions, while the remaineder are mixed within the rest of the data.\n",
    "\n",
    "Note: I have only used 10,000 of the 284,315 normal transactions for this visualization. I would have liked to of used more, but my laptop crashes if many more than 10,000 transactions are included. With only 3.15% of the data being used, there should be some accuracy to this plot, but I am confident that the layout would look different if all of the transactions were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set df_used to the fraudulent transactions' dataset.\n",
    "data_used = Fraud\n",
    "\n",
    "#Add 10,000 normal transactions to df_used.\n",
    "data_used = pd.concat([data_used, Normal.sample(n = 10000)], axis = 0)\n",
    "\n",
    "#Scale features to improve the training ability of TSNE.\n",
    "data_used_std = standard_scaler.fit_transform(data_used)\n",
    "\n",
    "#Set y_used equal to the target values.\n",
    "y_used = data_used.ix[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_2d_used = tsne.fit_transform(data_used_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_map = {1:'red', 0:'blue'}\n",
    "plt.figure()\n",
    "for idx, cl in enumerate(np.unique(y_used)):\n",
    "    plt.scatter(x=x_test_2d_used[y_used==cl,0], \n",
    "                y=x_test_2d_used[y_used==cl,1], \n",
    "                c=color_map[idx], \n",
    "                label=cl)\n",
    "plt.xlabel('X in t-SNE')\n",
    "plt.ylabel('Y in t-SNE')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('t-SNE visualization of test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the work we did in the feature engineering stage of this analysis has been for the best. We can see that the fraudulent transactions are all part of a group of points. This suggests that it is easier for a model to identify the fraudulent transactions in the testing data, and to learn about the traits of the fraudulent transactions in the training data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
