{
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "cells": [
    {
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "creditcard.csv\n\n"
        }
      ],
      "execution_count": 8,
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom sklearn.preprocessing import StandardScaler # for preprocessing the data\nfrom sklearn.ensemble import RandomForestClassifier # Random forest classifier\nfrom sklearn.tree import DecisionTreeClassifier # for Decision Tree classifier\nfrom sklearn.svm import SVC # for SVM classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold, cross_val_score\n#from sklearn.cross_validation import train_test_split # to split the data\n#from sklearn.cross_validation import KFold # For cross vbalidation\nfrom sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\nfrom sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\nfrom sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
      "metadata": {
        "_cell_guid": "0aae5368-b9be-47d1-aa02-30fe55036c05",
        "_uuid": "a37a7af8f9e9d274851fcb1a47c3c8fe44168e13",
        "trusted": false,
        "_execution_state": "idle"
      },
      "cell_type": "code"
    },
    {
      "metadata": {
        "collapsed": false,
        "_uuid": "9d48e54637ddaaaa5cfde4f277ff340cd1e062ab",
        "_execution_state": "idle"
      },
      "source": "data = pd.read_csv(\"../input/creditcard.csv\",header = 0)\n",
      "execution_count": 9,
      "cell_type": "code",
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": false,
        "_uuid": "4676135f2593511796b62e34333ef531c5f53771",
        "_execution_state": "idle"
      },
      "source": "#SVM\nsvc = SVC(C=1, kernel='linear')\nsvc2 = SVC(C=1, kernel='polynomial')\nsvc3 = SVC(C=1, kernel='rbf')\nsvc4 = SVC(C=1, kernel='sigmoid')\n\n#RF, clf = classifier\nclf = RandomForestClassifier(n_estimators=100, n_jobs=2, min_samples_split=2, random_state=0)\n#estimator = nb of free in forest, nbjobs = parallel calcul using cpu\n#scores = cross_val_score(clf, X, y)\n#scores.mean()    \n\n#clf.fit (x,y)...\n\nclf2 = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)\n#scores = cross_val_score(clf, X, y)\n#scores.mean()                             \n\nclf3 = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)\n#scores = cross_val_score(clf, X, y)\n#scores.mean() > 0.999\n\n",
      "execution_count": 10,
      "cell_type": "code",
      "outputs": []
    }
  ]
}